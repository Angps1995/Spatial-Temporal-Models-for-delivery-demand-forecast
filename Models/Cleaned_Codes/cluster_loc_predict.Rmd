---
title: "3 Step Approach, Clustering by location"
output: html_notebook
---

# Load Libraries and dataset
```{r}
library(tscount)
library(tseries)
library(urca)
library(factoextra)
library(vars)
library(BigVAR)
library(BBmisc)
library(amap)
library(gstar)
set.seed(1234)

#Load dataset
full_df <- read.csv("/home/angps/Documents/Thesis/Data/full_df_with_exo.csv")
df_atleast_50cts <- read.csv("/home/angps/Documents/Thesis/Data/df_>=50_with_exo.csv")
df_atleast_50cts_endo <- read.csv("/home/angps/Documents/Thesis/Data/data_>=50cts.csv")
loc_df <- read.csv("/home/angps/Documents/Thesis/Data/location_map.csv")
# index where locations have at least 50 non-zero counts
index_loc_atleast50 <- c(19,  23,  38,  43,  44,  53,  58,  62,  79,  89,  90,  93,  98,
            105, 109, 111, 123, 141, 155, 159, 162, 163, 233, 241, 243, 301,
            368, 397, 413, 441, 511, 559, 577, 680, 684, 688, 696, 707, 732,
            753, 777, 795)  
mini_loc_df <- loc_df[index_loc_atleast50,]
rownames(mini_loc_df) <- mini_loc_df$location
rownames(loc_df) <- loc_df$location

# Split to training/testing
train_small <- df_atleast_50cts_endo[,1:198]
test_small <- df_atleast_50cts_endo[,199:204]
train_full <- full_df[1:839,1:198]
test_full <- full_df[1:839,199:204]
```

# Implementation of functions used in this script
```{r}
stationary_test = function(df) {
    "
    Test stationrity of time series of each clusters and return how many clusters with stationary time series.
    Inputs:
      df: dataframe (where rows represent each timestep, columns represent individual cluster)
    Output:
      Number of stationary clusters/Total clusters
    "
   num_locs = dim(df)[2]  # number of clusters
   stationary_ct <- 0
   for (i in c(1 : num_locs)) {  # For each clusters
       adf_result <- suppressWarnings(adf.test(df[, i]))  # Apply adf test first 198 values as training set has 198 values
       p_val <- adf_result$p.value  # get p_value of adf test
       if (p_val <= 0.05 || is.nan(p_val)) {  # If stationary
           stationary_ct = stationary_ct + 1
       }
   }
   print(paste0("Number of stationary clusters/Total Clusters: ", stationary_ct, " / " , num_locs))
}

assign_clust_demand = function(clusters, clust_pred, train_df) {
    "
    Calculate past distribution of demand of the locations in each cluster, and use the distribution to reassign the total demand of each cluster to the locations. 
    Inputs:
      clusters: List containing the location index for each cluster
      clust_pred: Predicted values for each cluster
      train_df: Training dataframe
    Output:
      Dataframe containing predicted demand for each location
    "
    num_clust <- dim(clust_pred)[2]
    pred <- matrix(0, nrow = 6, ncol = dim(train_df)[1])  
    for (i in c(1:num_clust)) {
      clust_ind <- clusters[[i]]  
      clust_order_by_loc <- rowSums(train_df[clust_ind,])
      for (j in c(1:length(clust_ind))) {
          loc_prop <- clust_order_by_loc[j]/sum(clust_order_by_loc)
          for (t in c(1:6)) {
              clust_total_order <- clust_pred[t, i]
              ind <- clust_ind[j]
              pred[t, ind] <- loc_prop * clust_total_order
          }
        }
    } 
    return (pred) 
}

assign_cluster_by_loc = function(loc_df, ori_df, num_clust) {
    "
    Cluster by geographical locations, aggregate the locations into clusters where the cluster demand is the summation of all its locations' demand
    Inputs:
      loc_df: Location df
      ori_df: Original df to get orignal values
      num_clust: Number of clusters
    Output:
      List containing:
        cluster_df: Dataframe containing clusters and their respective aggregated (by sum) time series 
        cluster_ind: List containing the location index for each cluster
    "
    km <- kmeans(loc_df[,c(2:3)], centers = num_clust)  # Cluster using latitude and longitude
    clusters <- list()
    df_cols <- list()
    for (i in c(1 : num_clust)) {
        clust <- which(km$cluster %in% c(i))  # get location indices for each cluster
        clusters[[i]] <- clust
        cluster_orders <- colSums(ori_df[clust,])  # sum up all the locations' demand in the cluster
        df_cols[[i]] <- cluster_orders
    } 
    cluster_df <- data.frame(df_cols)
    return (list("cluster_df" = cluster_df, "cluster_ind" = clusters))
}

fit_and_predict_var = function(diff_df, cluster_df, p, struct, T1, T2, num_clusters) {
    "
    Fit VAR on clusters and predict the total demand for each cluster
    Inputs:
      diff_df: Dataframe of the differenced series
      cluster_df: Dataframe containing clusters and their respective aggregated (by sum) time series 
      p: Maximum lag order
      struct: Choice of penalty structure
      T1: Index of time series in which to start cross validation
      T2: Index of times series in which to start forecast evaluation
      num_clusters: Number of clusters 
    Output:
      prediction for each cluster
    "
    model = constructModel(as.matrix(diff_df), p = p, struct = struct, gran = c(25,10), T1 = T1, T2 = T2)
    var_model <- cv.BigVAR(model)  # Fit VAR model
    cluster_diff_pred <- tail(var_model@fitted,6)  # Get predictions of the differences
    prev <- cluster_df[198,1:num_clusters]  # get previous values
    cluster_pred <- prev + cluster_diff_pred[1, 1:num_clusters]  # convert to original values
    prev <- prev + cluster_diff_pred[1, 1:num_clusters]
    for (i in c(2:6)) {  # Repeat for the remaining timesteps
      cluster_pred <-rbind(cluster_pred, prev + cluster_diff_pred[i, 1:num_clusters])
      prev <- prev + cluster_diff_pred[i, 1:num_clusters]
    }
    return (cluster_pred)
}


fit_and_predict_star = function(diff_df, cluster_df, ar_term, ma_term, num_clusters) {
    "
    Fit STAR on clusters and predict the total demand for each cluster
    Inputs:
      diff_df: Dataframe of the differenced series
      cluster_df: Dataframe containing clusters and their respective aggregated (by sum) time series 
      ar_term: AR term
      ma_term: MA term
    Output:
      prediction for each cluster
    "
  
    # Small subset
    num_per_train = dim(cluster_df)[1]
    num_loc_train = dim(cluster_df)[2]
    
    # set uniform weights
    weight <- diag(-1, num_loc_train, num_loc_train) + matrix(1, num_loc_train, num_loc_train)
    weight = weight/(num_loc_train)
    # Fit STAR models
    model <- gstar(diff_df, weight = weight, p = ar_term, d = ma_term, est = "OLS")
    
    # predict 6 step ahead
    cluster_diff_pred <- predict(model, n = 6)
    prev <- cluster_df[198,1:num_clusters]  # get previous values
    cluster_pred <- prev + cluster_diff_pred[1, 1:num_clusters]  # convert to original values
    prev <- prev + cluster_diff_pred[1, 1:num_clusters]
    for (i in c(2:6)) {  # Repeat for the remaining timesteps
      cluster_pred <-rbind(cluster_pred, prev + cluster_diff_pred[i, 1:num_clusters])
      prev <- prev + cluster_diff_pred[i, 1:num_clusters]
    }
    return (cluster_pred)
}

reassign_demand_to_loc_and_evaluate = function(cluster_pred, cluster_ind, train_df, ori_df) {
    "
    Reassign demand to each location and evaluate MSE
    Inputs:
      cluster_pred: Dataframe containing predicted total demand for each cluster
      cluster_ind: List containing location indices of each cluster
      train_df: Training data (only training timesteps)
      ori_df: Original dataset containing all timesteps
    Output:
      List containing:
        Errors_array: Array of errors
        Fitted_Values: Array of the fitted/predicted values
        MSE: Mean squared error
        Quadratic(Brier) Score: Quadratic Score
    "
    pred <- assign_clust_demand(cluster_ind, cluster_pred, train_df)
    num_locs <- dim(pred)[2]
    errors <- 0
    quad_score <- 0
    error_arr <- c()
    fitted_val <- c()
    for (i in c(1:6)) {
        curr_pred <- pred[i, 1:num_locs]
        act <- ori_df[1:num_locs,198 + i]
        error_arr <- c(error_arr, c(curr_pred - act))
        fitted_val <- c(fitted_val, curr_pred)
        error <- sum((curr_pred - act) ^ 2)
        errors <- errors + error
        prev_pred <- curr_pred
        for (j in c(1:num_locs)) {if (isFALSE(is.nan(suppressWarnings(scoring(act[j], curr_pred[j], distr=c("poisson"))['quadratic'][['quadratic']])))) {
          quad_score <- quad_score + scoring(act[j], curr_pred[j], distr=c("poisson"))['quadratic']}}
    }
    return (list("Errors_array" = error_arr, "Fitted_Values" = fitted_val, "MSE" = errors/6, 'Quadratic(Brier) Score' = quad_score/6))
}

get_clustering_by_loc_result = function(num_clust, loc_df, ori_df, train_df, pred_method, p=6, struct="Basic", T1=156, T2=198) {
    "
    Main function to perform the 3 step approach using clustering by location
    Inputs:
      num_clust: Number of clusters
      loc_df: Location dataframe containing latitude longitude
      ori_df: Original dataframe of all timesteps
      train_df: Training set 
      pred_method: 'VAR' or 'STAR'
      p: Maximum lag order
      struct: Choice of penalty structure
      T1: Index of time series in which to start cross validation
      T2: Index of times series in which to start forecast evaluation
    Output:
      Mean Squared Error 
      Quadratic Score
    "
    # Perform clustering
    ClusterResult <- assign_cluster_by_loc(loc_df=loc_df, ori_df=ori_df, num_clust = num_clust)
    cluster_df <- ClusterResult$cluster_df
    cluster_ind <- ClusterResult$cluster_ind
    # Test for stationarity 
    stationary_test(cluster_df)
    print("After Differencing")
    # Perform differenncing and test stationarity
    colnames(cluster_df) = c(1:num_clust)
    rownames(cluster_df) <- c(1:204)
    diff_small_df <- data.frame(diff(as.matrix(cluster_df), differences=1))
    stationary_test(diff_small_df)
    if (pred_method == "VAR") {
        # Build a VAR model and predict the total cluster demand
        cluster_pred <- fit_and_predict_var(diff_df=diff_small_df, cluster_df=cluster_df, p=p, struct=struct, T1=T1, T2=T2, num_clusters=num_clust)
    } else if (pred_method == "STAR") {
        # Build a STAR model and predict the total cluster demand
        cluster_pred <- fit_and_predict_star(diff_df=diff_small_df, cluster_df=cluster_df, ar_term=6, ma_term=0, num_clusters=num_clust)
    }

    # Reassign the demand of each cluster to its respective locations and evaluate MSE
    result <- reassign_demand_to_loc_and_evaluate(cluster_pred = cluster_pred, cluster_ind = cluster_ind, train_df=train_df, ori_df=ori_df)
    error_arr <- result$Errors_array
    MSE <- result$MSE
    quad_score = result$`Quadratic(Brier) Score`
    fitted_val <- result$Fitted_Values
    print(paste0("MSE of clustering by location using ", num_clust, " clusters: ", MSE))
    print(paste0("Quadratic Score of clustering by correlation using ", num_clust, " clusters: ", quad_score))
    return (list("MSE" = MSE, "quad_score" = quad_score))
}
```

# Apply on small dataset (VAR)

```{r eval=FALSE}
clusters <- c(2:12)
MSE <- c()
quad_score <- c()
for (i in clusters) {
    res <- get_clustering_by_loc_result(num_clust=i, loc_df = mini_loc_df, ori_df = df_atleast_50cts_endo, train_df = train_small, pred_method="VAR")
    MSE <-c(MSE, res$MSE)
    quad_score <- c(quad_score, res$quad_score)
}
```

# Apply on small dataset (STAR)

```{r eval=FALSE}
clusters <- c(2:12)
MSE <- c()
quad_score <- c()
for (i in clusters) {
    res <- get_clustering_by_loc_result(num_clust=i, loc_df = mini_loc_df, ori_df = df_atleast_50cts_endo, train_df = train_small, pred_method="STAR")
    MSE <-c(MSE, res$MSE)
    quad_score <- c(quad_score, res$quad_score)
}
```

# Apply on full dataset (VAR) (Try clustering groups 2-12)

```{r eval=FALSE}
clusters <- c(2:12)
MSE <- c()
quad_score <- c()
for (i in clusters) {
    res <- get_clustering_by_loc_result(num_clust=i, loc_df = loc_df, ori_df = full_df[1:839,], train_df = train_full, pred_method='VAR')
    MSE <-c(MSE, res$MSE)
    quad_score <- c(quad_score, res$quad_score)
}
plot(clusters, MSE, main="MSE against different number of clusters",cex.main=1.2, cex.lab=1.3)
lines(clusters, MSE)
dev.copy(jpeg,filename="/home/angps/Documents/Thesis/Report/Images/Cluster_Loc_MSE_plot.jpg");
dev.off ();

plot(clusters, quad_score, main="Quad Score against different number of clusters",cex.main=1.2, cex.lab=1.3)
lines(clusters,quad_score)
dev.copy(jpeg,filename="/home/angps/Documents/Thesis/Report/Images/Cluster_Loc_quad_plot.jpg");
dev.off ();
```

# Apply on full dataset (STAR) (Try clustering groups 2-12)

```{r eval=FALSE}
clusters <- c(2:12)
MSE <- c()
quad_score <- c()
for (i in clusters) {
    res <- get_clustering_by_loc_result(num_clust=i, loc_df = loc_df, ori_df = full_df[1:839,], train_df = train_full, pred_method='STAR')
    MSE <-c(MSE, res$MSE)
    quad_score <- c(quad_score, res$quad_score)
}
plot(clusters, MSE, main="MSE against different number of clusters",cex.main=1.2, cex.lab=1.3)
lines(clusters, MSE)
dev.copy(jpeg,filename="/home/angps/Documents/Thesis/Report/Images/Cluster_STAR_Loc_MSE_plot.jpg");
dev.off ();

plot(clusters, quad_score, main="Quad Score against different number of clusters",cex.main=1.2, cex.lab=1.3)
lines(clusters,quad_score)
dev.copy(jpeg,filename="/home/angps/Documents/Thesis/Report/Images/Cluster_STAR_Loc_quad_plot.jpg");
dev.off ();
```



